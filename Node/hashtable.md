# hashtable

`hashtable`在插入、删除、搜寻等操作上都有常数平均时间的表现。

## 概述

[维基百科](https://zh.wikipedia.org/wiki/%E5%93%88%E5%B8%8C%E8%A1%A8)

`hash table` 可提供对任何有名项的存取操作和删除操作。由于操作对象是有名项，所以`hash table`也可被视为一种字典结构。**这种结构的用意在于提供常数时间之基础操作**，就像`stack`和`queue`那样。

`hash table` 是根据键（Key）而直接访问在内存储存位置的数据结构。也就是说，它通过计算出一个键值的函数，将所需查询的数据映射到表中一个位置来让人访问，这加快了查找速度。这个映射函数称做散列函数，存放记录的数组称做**散列表**。



### 基本概念：

- **散列函数**：若关键字为k，则其值存放在f(K)的存储位置上。由此，不需比较便可直接取得所查记录。称这个对应关系f为散列函数，按这个思想建立的表为散列表。
- **散列地址和冲突**：对不同的关键字可能得到同一散列地址，即$k_1 != K_2$，而$f(k_1) = f(k_2)$这种现象称为冲突(Collision）。具有相同函数值的关键字对该散列函数来说称做同义词。综上所述，根据散列函数f(K)和处理冲突的方法将一组关键字映射到一个有限的连续的地址集（区间）上，并以关键字在地址集中的“像”作为记录在表中的存储位置，这种表便称为散列表，这一映射过程称为散列造表或散列，所得的存储位置称散列地址。
- **均匀散列函数：**若对于关键字集合中的任一个关键字，经散列函数映象到地址集合中任何一个地址的概率是相等的，则称此类散列函数为均匀散列函数 (Uniforrp Hash function），这就使关键字经过散列西数得到一个“随机的地址”，从而減少冲突。
- **负载系数：**散列表的负载系数定义为：$\alpha = 填入表中的元素个数/散列表的长度$。$\alpha$是散列表装满程度的标志因子。由于表长是定值，$\alpha$与“填入表中的元素个数”成正比，所以，$\alpha$越大，表明填入表中的元素越多，产生冲突的可能性就越大；反之，$\alpha$越小，标明填入表中的元素越少，产生冲突的可能性就越小。实际上，散列表的平均查找长度是载荷因子$\alpha$的函数，只是不同处理冲突的方法有不同的函数。



### 构造散列函数

散列函数能使对一个数据序列的访问过程更加迅速有效，通过散列函数，数据元素将被更快定位。

1. **直接定址法：**取关键字或关键字的某个线性函数值为散列地址。即$hash(k) = k$或$hash(k) = a*k +b$,其中a b为常数。（这种散列函数叫做自身函数）
2. 数字分析法：假设关键字是以内基的数，并且哈希表中可能出现的关键字都是事先知道的，则可取关键字的若千数位组成哈希地址。
3. **平方取中法：**取关键字平方后的中间几位为哈希地址。通常在选定哈希函数时不一定能知道关键字的全部情况，取其中的哪几位也不一定合适，而一个数平方后的中间几位数和数的每一位都相关，由此使随机分布的关键字得到的哈希地址也是随机的。取的位数由表长决定。
4. **折叠法：**将关键字分割成位数相同的几部分(最后一部分的位数可以不同），然后取这几部分的叠加和（舍去进位）作为哈希地址。
5. **随机数法**
6. **除留余数法：**取关键字被某个不大于散列表表长m的数p除后所得的余数为散列地址。即$hash(k) = k\mod p,p<=m$。不仅可以对关键字直接取模，也可在折叠法、平方取中法等运算之后取模。对p的选择很重要，一般取素数或m，若p选择不好，容易产生冲突。



### 处理冲突：

**线性探测法：**当hash function 计算出某个元素的插人位置，而该位置上的空间已不再可用时，我们应该怎么办？最简单的办法就是循序往下一一寻找（如果到达尾端，就绕到头部继续寻找），直到找到一个可 用空间为止。只要表格（亦即array）足够大，总是能够找到一个安身立命的空间，但是要花多少时间就很难说了。进行元素搜寻操作时，道理也相同，如果 `hash function` 计算出来的位置上的元素值与我们的搜寻目标不符，就循序往下一一寻找，直到找到吻合者，或直到遇上空格元素。至于元素的刷除，必须采用惰性删除 (lazy deletion），也就是只标记删除记号，实际删除操作则待表格重新整理 （rehashing）时再进行——这是因为hash table 中的每一个元素不仅表述它自己，也关系到其它元素的排列。

**二次探测：**二次探测主要用来解决主集团的问题。其命名由来是因为解决碰撞问题的方程式$F(i) = i^2$是个二次方程式。更明确的说，如果`hash function`计算出新元素的位置为H，而该位置实际上已经被使用，那么我们就依序尝试$H+1^2,H+2^2,H+3^2,...,H+i^2$。辛运的是，如果我们假设表格大小为质数 (prime），而且永远保持负载系数在0.5以下（也就是说超过 0.5 就重新配置并重新整理表格），那么就可以确定每插人一个新元素所需要的探測次数不多于2。

​	二次探测可以消除主集团 (primary clustering），却可能造成次集团 (secondary clustering）：两个元素经hash function 计算出来的位置若相同，则插人时所探测的位置也相同，形成某种浪费。消除次集团的办法当然也有，例如复式散列 (double hashing) .

**开链：**另一种与二次探测法分庭抗礼的，是所谓的开链 (separate chaining）法。这种做法是在每一个表格元素中维护一个iist:hash function 为我们分配某一个list，然后我们在那个 list 身上执行元素的插人、搜寻、删除等操作。虽然针对list 而进行的搜寻只能是一种线性操作，但如果 Tist 够短，速度还是够快。



## `hashtable`的桶（buckets）与节点(nodes)

<img src="hashtable.assets/截屏2023-06-11 17.01.27.png" alt="截屏2023-06-11 17.01.27" style="zoom:50%;" />

`hash table`表格内的元素为桶子(bucket），此名称的大约意义是，表格内的每个单元，涵盖的不只是个节点（元素），甚至可能是一“桶”节点。



# hash_set



## 概述

SGI 则是在 STL 标准规格之外另又提供了一个所谓的 hash_set，以hashtable为底层机制。由于hash_set 所供应的操作接口， hashtable都提供了，所以几乎所有的hash_set 操作行为，都只是转调用 hashtabie 的操作行为而已。

**hash_set元素的键值就是实值，实值就是键值。**



## hash_map



概述

SGI 在STL 标准规格之外，另提供了一个所谓的 hash_map， 以 hashtable 为底层机制。由于 hash_map 所供应的操作接口，hashtable 都提供了，所以几乎所有的hash_map 操作行为，都只是转调用hashtable 的操作行为而己。

远用map，为的是能够根据键值快速搜寻元素。这一点，不论其底层是RB-tree 或是hashtable，都可以达成任务。但是请注意，RB-tree 有自动排序功能而 hashtable没有，反应出来的结果就是，map 的元素有自动排序功能而 hast_map 没有。

map的特性是，**每一个元素都同时拥有一个实值（vale）和一个键值 (key）**。这一点在hash_map 中也是一样的。hash_map的使用方式，和map完全相同。



